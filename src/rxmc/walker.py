from pathlib import Path

import numpy as np

from .param_sampling import SamplingConfig
from .corpus import Corpus


class Walker:
    """
    A class that encapsulates the sampling configuration for a Bayesian
    inference problem, including the physical model and likelihood model
    configurations. It manages the sampling process for both the physical model
    and the likelihood model parameters, alternating between each model in
    a Gibbs sampling framework.
    """

    def __init__(
        self,
        model_sample_conf: SamplingConfig,
        corpus: Corpus,
        likelihood_sample_confs: list[SamplingConfig] = [],
        rng: np.random.Generator = np.random.default_rng(42),
    ):
        """
        Initialize the SamplingConfig with a list of samplers.

        Parameters:
        ----------
        physical_model_samplers: Sampler
            A Sampler object for physical model parameters.
        corpus: Corpus
            A Corpus object containing the data for which the likelihood
            model is evaluated.
        likelihood_model_samplers: list[Sampler]
            A list of Sampler objects for likelihood model parameters.
            Corresponds to the order of `corpus.parametric_constraints`.
        rng: np.random.Generator, optional
            A random number generator for reproducibility. Defaults to a new
            default_rng with a fixed seed.
        """

        # constant attributes
        self.model_sample_conf = model_sample_conf
        self.likelihood_sample_confs = likelihood_sample_confs
        self.corpus = corpus
        self.rng = rng

        self.gibbs_sampling = len(self.likelihood_sample_confs) > 0

        if self.corpus.model_params != self.model_sample_conf.params:
            raise ValueError(
                "Inconsistent physical model parameters between "
                "'corpus' and 'model_sample_conf'"
            )

        if len(self.likelihood_sample_confs) != len(self.corpus.parametric_constraints):
            raise ValueError(
                "The lists 'likelihood_sample_confs' and "
                "'corpus.parametric_constraints' must correspond!"
            )
        for i, conf in enumerate(self.likelihood_sample_confs):
            constraint = self.corpus.parametric_constraints[i]
            if constraint.likelihood.params != conf.params:
                raise ValueError(
                    "Inconsistent likelihood model parameters"
                    f"between 'likelihood_sample_confs[{i}]' and "
                    f"'corpus.parametric_constraints[{i}]'"
                )

        # attributes that are updated during sampling
        # each time `self.walk` is called these records will be updated
        self.model_chain = np.empty((0,len(self.model_sample_conf.params)))
        self.likelihood_chain = [np.empty((0,len(sampler.params))) for sampler in self.likelihood_sample_confs]
        self.current_model_chain = self.model_sample_conf.starting_location
        self.current_likelihood_chain = [
            conf.starting_location for conf in self.likelihood_sample_confs
        ]
        self.log_posterior_record = []
        self.log_posterior_record_lm = [[] for _ in self.likelihood_sample_confs]

    def run_model_batch(self, n_steps, x0, likelihood_params=[]):
        """
        Walks the model parameter space for fixed values of the
        `likelihood_params`

        Parameters:
        ----------
        n_steps: int
            The number of steps to run for the model sampling.
        x0: np.ndarray
            The starting location for the model sampling.
        likelihood_params: list[tuple]
            A list of fixed values of the parameters for each of the
            parametric likelihood models, corresponding to the order
            of `self.likelihood_sample_confs`

        Returns:
        -------
        batch_chain: np.ndarray
            The parameter chain generated by the model sampling algorithm.
        logp: np.ndarray
            The log probabilities of the parameter chain.
        accepted: float
            The acceptance rate of the model sampling algorithm.
        """
        batch_chain, logp, accepted = self.model_sample_conf.sampling_algorithm(
            x0=x0,
            n_steps=n_steps,
            log_posterior=lambda x: self.log_posterior(x, likelihood_params),
            propose=self.model_sample_conf.proposal,
            rng=self.rng,
        )
        return batch_chain, logp, accepted

    def run_likelihood_batches(self, n_steps, starting_locations, model_params):
        """
        Walks each of the likelihood parameter spacers one by one, for a
        fixed value of `model_params`

        Parameters:
        ----------
        n_steps: int
            The number of steps to run for each likelihood model.
        starting_locations: list[np.ndarray]
            A list of starting locations for each likelihood model.
        model_params: tuple
            A fixed value of the parameters for the physical model

        Returns:
        -------
        list[np.ndarray]
            A list of parameter chains for each likelihood model.
        logp : list[np.ndarray]
            A list of log probabilities for each likelihood model.
        accepted : list[float]
            A list of acceptance rates for each likelihood model.
        """
        chains = []
        logp = []
        accepted = []
        for i, lm_conf in enumerate(self.likelihood_sample_confs):
            constraint = self.corpus.parametric_constraints[i]

            # precompute the model prediction for just this constraint,
            # as the physical model parameters (and thus the physical
            # model prediction) will be fixed for this walk
            ym = constraint.predict(model_params)

            # the posterior pdf of this walk only accounts for the
            # observables in the constraint containing the likelihood
            # model whose parameters we're sampling, rather than the
            # whole corpus
            def log_posterior(x):
                return lm_conf.prior.logpdf(x) + constraint.marginal_log_likelihood(
                    ym, x
                )

            # run a chain over the parameter space of just this
            # likelihood model
            chain, logp, accepted = lm_conf.sampling_algorithm(
                x0=starting_locations[i],
                n_steps=n_steps,
                log_posterior=log_posterior,
                propose=lm_conf.proposal,
                rng=self.rng,
            )
            chains.append(chain)
            logp.append(logp)
            accepted.append(accepted)

        return chains, logp, accepted

    def log_likelihood(self, model_params, likelihood_params):
        return self.corpus.log_likelihood(model_params, likelihood_params)

    def log_posterior(self, model_params, likelihood_params):
        return self.log_likelihood(model_params, likelihood_params) + self.log_prior(
            model_params, likelihood_params
        )

    def log_prior(self, model_params, likelihood_params):
        """
        Returns the log-prior probability of the model parameters and
        likelihood parameters.

        Parameters:
        ----------
        model_params: tuple
            The parameters of the physical model.
        likelihood_params: list[tuple]
            A list of tuples containing additional parameters for the
            likelihood model for each constraint.

        Returns:
        -------
        float
            The log-prior probability.
        """
        return self.model_sample_conf.prior.logpdf(model_params) + sum(
            lm.prior.logpdf(likelihood_params[i])
            for i, lm in enumerate(self.likelihood_sample_confs)
        )

    def walk(
        self,
        n_steps: int,
        burnin: int = 0,
        batch_size: int = None,
        verbose: bool = True,
        output: Path = None,
    ):
        """
        Runs the MCMC chain with the specified parameters. Updates
        the values of `self.current_likelihood_chain`, `self.current_model_chain`,
        `self.model_chain`, `self.likelihood_chain`, `self.log_posterior_record`, and
        `self.log_posterior_record_lm`.

        Parameters:
        -----------
            n_steps : int
                Total number of active steps for the MCMC chain.
            batch_size : int
                Number of steps per batch.
            burnin : int
                Number of extra burn-in steps to do before active steps
            verbose : bool
                Flag to print extra logging information.
            output : Path, optional
                Output directory for saving chain batches.


        """
        if batch_size is not None:
            rem_burn = burnin % batch_size
            n_burn_batches = burnin // batch_size
            burn_batches = n_burn_batches * [batch_size] + (rem_burn > 0) * [rem_burn]

            rem = n_steps % batch_size
            n_full_batches = n_steps // batch_size
            batches = n_full_batches * [batch_size] + (rem > 0) * [rem]
        else:
            batches = [n_steps]
            burn_batches = [burnin]

        if burnin == 0:
            burn_batches = []

        pm_chain = []
        pm_logp = []
        lm_chains = [[] for _ in self.likelihood_sample_confs]
        lm_logp = [[] for _ in self.likelihood_sample_confs]

        # burn in
        for i, steps_in_batch in enumerate(burn_batches):
            # Gibb's sample physical model parameters
            batch_chain, _, _ = self.run_model_batch(
                steps_in_batch,
                self.current_model_chain,
                self.current_likelihood_chain,
            )

            self.current_model_chain = batch_chain[-1]

            if self.gibbs_sampling:
                # Gibb's sample likelihood model parameters
                batch_chains, _, _ = self.run_likelihood_batches(
                    steps_in_batch,
                    self.current_likelihood_chain,
                    self.current_model_chain,
                )

                self.current_likelihood_chain = [c[-1] for c in batch_chains]

            if verbose:
                print(
                    f"Burn-in batch {i+1}/{len(burn_batches)}"
                    f" completed, {steps_in_batch} steps."
                )

        # do real walk
        accepted = 0
        accepted_lm = [0] * len(self.likelihood_sample_confs)
        for i, steps_in_batch in enumerate(batches):
            # Gibb's sample physical model parameters
            batch_chain, batch_logp, accepted_in_batch = self.run_model_batch(
                steps_in_batch,
                self.current_model_chain,
                self.current_likelihood_chain,
            )

            self.current_model_chain = batch_chain[-1]
            accepted += accepted_in_batch
            pm_chain.append(batch_chain)
            pm_logp.append(batch_logp)

            if self.gibbs_sampling:
                # Gibb's sample likelihood model parameters
                batch_chains, batch_logps, accepted_in_batch = (
                    self.run_likelihood_batches(
                        steps_in_batch,
                        self.current_likelihood_chain,
                        self.current_model_chain,
                    )
                )

                self.current_likelihood_chain = [c[-1] for c in batch_chains]
                for i in range(len(self.likelihood_sample_confs)):
                    accepted_lm[i] += accepted_in_batch[i]
                    lm_chains[i].append(batch_chains[i])
                    lm_logp[i].append(batch_logps[i])

            if verbose:
                msg = (
                    f"Batch: {i+1}/{len(batches)} completed, "
                    f"{steps_in_batch} steps. "
                    f"\n  Model parameter acceptance fraction: "
                    f"{accepted_in_batch/steps_in_batch:.3f}"
                )
                if self.gibbs_sampling:
                    msg += (
                        f"\n  Likelihood parameter acceptance fractions: "
                        f"{[a/steps_in_batch for a in accepted_lm]}"
                    )
                print(msg)

            # concatenate chains from each batch
            pm_chain = np.concatenate(pm_chain, axis=0)
            lm_chains = [np.concatenate(c) for c in lm_chains]
            pm_logp = np.concatenate(pm_logp, axis=0)
            lm_logp = [np.concatenate(c) for c in lm_logp]

            # concatenate full chains to the record
            self.model_chain = np.concatenate([self.model_chain, pm_chain], axis=0)
            self.likelihood_chain = [
                np.concatenate([old_chain, new_chain], axis=0)
                for old_chain, new_chain in zip(self.likelihood_chain, lm_chains)
            ]
            self.log_posterior_record = np.concatenate(
                [self.log_posterior_record, pm_logp], axis=0
            )
            self.log_posterior_record_lm = [
                np.concatenate([old_logp, new_logp], axis=0)
                for old_logp, new_logp in zip(self.log_posterior_record_lm, lm_logp)
            ]

            final_acceptance_frac = accepted / n_steps
            final_acceptance_frac_lm = [a / n_steps for a in accepted_lm]

            if self.gibbs_sampling:
                return final_acceptance_frac, final_acceptance_frac_lm
            else:
                return final_acceptance_frac
