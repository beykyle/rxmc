{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196a680f-91b8-4c45-8894-f56175a73082",
   "metadata": {},
   "source": [
    "# Some simple demos of approaches to Bayesian inference with unknown errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c549ae62-7f81-4a8e-a54e-a7331a298c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30661332-6457-453b-921c-845307984563",
   "metadata": {},
   "source": [
    "## Treat the error as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09057f21-a84a-4658-885f-7e4a36c6d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(y, x, m, b, sigma2, m_prior, b_prior, sigma2_prior):\n",
    "    \"\"\"\n",
    "    Calculate the log posterior given parameters.\n",
    "    \"\"\"\n",
    "    # Log likelihood\n",
    "    residuals = y - (m * x + b)\n",
    "    log_likelihood = -0.5 * np.sum(residuals**2 / sigma2) - (len(y) / 2) * np.log(\n",
    "        2 * np.pi * sigma2\n",
    "    )\n",
    "\n",
    "    # Log priors\n",
    "    log_prior_m = norm.logpdf(m, loc=m_prior[0], scale=np.sqrt(m_prior[1]))\n",
    "    log_prior_b = norm.logpdf(b, loc=b_prior[0], scale=np.sqrt(b_prior[1]))\n",
    "    log_prior_sigma2 = invgamma.logpdf(sigma2, a=sigma2_prior[0], scale=sigma2_prior[1])\n",
    "\n",
    "    return log_likelihood + log_prior_m + log_prior_b + log_prior_sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9958a043-b6df-4635-848f-d9800fecc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(\n",
    "    y,\n",
    "    x,\n",
    "    n_iterations=1000,\n",
    "    burn_in=200,\n",
    "    m_prior=(0, 10),\n",
    "    b_prior=(0, 10),\n",
    "    sigma2_prior=(1, 1),\n",
    "    proposal_std=(0.1, 0.1, 0.1),\n",
    "):\n",
    "    # Proposal distribution std deviation\n",
    "    prop_m, prop_b, prop_log_sigma2 = proposal_std\n",
    "\n",
    "    # Initialization\n",
    "    m_current = np.random.normal(m_prior[0], np.sqrt(m_prior[1]))\n",
    "    b_current = np.random.normal(b_prior[0], np.sqrt(b_prior[1]))\n",
    "    sigma2_current = invgamma.rvs(a=sigma2_prior[0], scale=sigma2_prior[1])\n",
    "\n",
    "    # Storage for samples\n",
    "    m_samples = []\n",
    "    b_samples = []\n",
    "    sigma2_samples = []\n",
    "\n",
    "    # Current log posterior\n",
    "    current_log_post = log_posterior(\n",
    "        y, x, m_current, b_current, sigma2_current, m_prior, b_prior, sigma2_prior\n",
    "    )\n",
    "\n",
    "    accepted = 0\n",
    "    for iteration in range(n_iterations):\n",
    "        # Propose new m and b\n",
    "        m_proposal = m_current + np.random.normal(0, prop_m)\n",
    "        b_proposal = b_current + np.random.normal(0, prop_b)\n",
    "        # Propose new sigma^2 using log proposal (ensures positivity)\n",
    "        log_sigma2_proposal = np.log(sigma2_current) + np.random.normal(\n",
    "            0, prop_log_sigma2\n",
    "        )\n",
    "        sigma2_proposal = np.exp(log_sigma2_proposal)\n",
    "\n",
    "        # Calculate log posterior for proposed values\n",
    "        proposed_log_post = log_posterior(\n",
    "            y,\n",
    "            x,\n",
    "            m_proposal,\n",
    "            b_proposal,\n",
    "            sigma2_proposal,\n",
    "            m_prior,\n",
    "            b_prior,\n",
    "            sigma2_prior,\n",
    "        )\n",
    "\n",
    "        # Acceptance probability\n",
    "        acceptance_prob = np.exp(proposed_log_post - current_log_post)\n",
    "        # Accept or reject\n",
    "        if np.random.rand() < acceptance_prob:\n",
    "            m_current, b_current, sigma2_current = (\n",
    "                m_proposal,\n",
    "                b_proposal,\n",
    "                sigma2_proposal,\n",
    "            )\n",
    "            current_log_post = proposed_log_post\n",
    "            accepted += 1\n",
    "\n",
    "        # Store samples after burn-in\n",
    "        if iteration >= burn_in:\n",
    "            m_samples.append(m_current)\n",
    "            b_samples.append(b_current)\n",
    "            sigma2_samples.append(sigma2_current)\n",
    "\n",
    "    return m_samples, b_samples, sigma2_samples, accepted / (n_iterations - burn_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23dc540c-c865-420c-9d1b-bf53065e034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance frac: 0.5863265306122449\n",
      "Estimated m: 2.96504916042215\n",
      "Estimated b: 3.967211455661518\n",
      "Estimated sigma^2: 1.996042291709049\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.normal(0, 1, 100)\n",
    "y_data = 3.0 * x_data + 4.0 + np.random.normal(0, np.sqrt(2), 100)\n",
    "\n",
    "# Define priors: (mean, variance) for normal, (alpha, beta) for inverse gamma\n",
    "m_prior = (4, 3)\n",
    "b_prior = (3, 3)\n",
    "sigma2_prior = (0.3, 3)\n",
    "\n",
    "# Run Metropolis-Hastings\n",
    "m_samples, b_samples, sigma2_samples, afrac = metropolis_hastings(\n",
    "    y_data,\n",
    "    x_data,\n",
    "    m_prior=m_prior,\n",
    "    b_prior=b_prior,\n",
    "    sigma2_prior=sigma2_prior,\n",
    "    proposal_std=(0.1, 0.1, 0.1),\n",
    "    n_iterations=10000,\n",
    ")\n",
    "print(f\"acceptance frac: {afrac}\")\n",
    "print(\"Estimated m:\", np.mean(m_samples))\n",
    "print(\"Estimated b:\", np.mean(b_samples))\n",
    "print(\"Estimated sigma^2:\", np.mean(sigma2_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7969e-9a76-4929-a0b8-b318e6cdb3ba",
   "metadata": {},
   "source": [
    "## Alternate sampling error and model parameters in batches\n",
    "This is useful when evaluating the model is compuationall expensive relative to evaluting the log likelihood conditional on a given model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee9f6bb-acc9-49c3-877d-82614ea46d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior_batch(y, y_model, sigma2, m_prior, b_prior, sigma2_prior):\n",
    "    \"\"\"\n",
    "    Calculate the log posterior given parameters, considering fixed y_model.\n",
    "    \"\"\"\n",
    "    # Log likelihood\n",
    "    residuals = y - y_model\n",
    "    log_likelihood = -0.5 * np.sum(residuals**2 / sigma2) - (len(y) / 2) * np.log(\n",
    "        2 * np.pi * sigma2\n",
    "    )\n",
    "\n",
    "    # Assuming m_prior and b_prior are already incorporated during m and b updates\n",
    "    # Log prior for sigma^2\n",
    "    log_prior_sigma2 = invgamma.logpdf(sigma2, a=sigma2_prior[0], scale=sigma2_prior[1])\n",
    "\n",
    "    return log_likelihood + log_prior_sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e563c3-156a-44a0-9a26-62b4f1babe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_batched(\n",
    "    y,\n",
    "    x,\n",
    "    n_iterations=1000,\n",
    "    burn_in=200,\n",
    "    batch_size=10,\n",
    "    m_prior=(0, 10),\n",
    "    b_prior=(0, 10),\n",
    "    sigma2_prior=(1, 1),\n",
    "    proposal_std=(0.1, 0.1, 0.1),\n",
    "):\n",
    "    prop_m, prop_b, prop_log_sigma2 = proposal_std\n",
    "\n",
    "    # Initialization\n",
    "    m_current = np.random.normal(m_prior[0], np.sqrt(m_prior[1]))\n",
    "    b_current = np.random.normal(b_prior[0], np.sqrt(b_prior[1]))\n",
    "    sigma2_current = invgamma.rvs(a=sigma2_prior[0], scale=sigma2_prior[1])\n",
    "    y_model = m_current * x + b_current\n",
    "\n",
    "    # Storage for samples\n",
    "    m_samples = []\n",
    "    b_samples = []\n",
    "    sigma2_samples = []\n",
    "    accepted = 0\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration % (2 * batch_size) < batch_size:\n",
    "            # Update m and b\n",
    "            m_proposal = m_current + np.random.normal(0, prop_m)\n",
    "            b_proposal = b_current + np.random.normal(0, prop_b)\n",
    "            y_model_proposal = m_proposal * x + b_proposal\n",
    "\n",
    "            # Calculate and compare log posterior\n",
    "            current_log_post = log_posterior_batch(\n",
    "                y, y_model, sigma2_current, m_prior, b_prior, sigma2_prior\n",
    "            )\n",
    "            proposed_log_post = log_posterior_batch(\n",
    "                y, y_model_proposal, sigma2_current, m_prior, b_prior, sigma2_prior\n",
    "            )\n",
    "\n",
    "            acceptance_prob = np.exp(proposed_log_post - current_log_post)\n",
    "            if np.random.rand() < acceptance_prob:\n",
    "                m_current, b_current, y_model = m_proposal, b_proposal, y_model_proposal\n",
    "                accepted += 1\n",
    "\n",
    "        else:\n",
    "            # Update sigma^2\n",
    "            log_sigma2_proposal = np.log(sigma2_current) + np.random.normal(\n",
    "                0, prop_log_sigma2\n",
    "            )\n",
    "            sigma2_proposal = np.exp(log_sigma2_proposal)\n",
    "\n",
    "            # Calculate and compare log posterior (holding m and b fixed)\n",
    "            current_log_post = log_posterior_batch(\n",
    "                y, y_model, sigma2_current, m_prior, b_prior, sigma2_prior\n",
    "            )\n",
    "            proposed_log_post = log_posterior_batch(\n",
    "                y, y_model, sigma2_proposal, m_prior, b_prior, sigma2_prior\n",
    "            )\n",
    "\n",
    "            acceptance_prob = np.exp(proposed_log_post - current_log_post)\n",
    "            if np.random.rand() < acceptance_prob:\n",
    "                sigma2_current = sigma2_proposal\n",
    "                accepted += 1\n",
    "\n",
    "        # Store samples after burn-in\n",
    "        if iteration >= burn_in:\n",
    "            m_samples.append(m_current)\n",
    "            b_samples.append(b_current)\n",
    "            sigma2_samples.append(sigma2_current)\n",
    "\n",
    "    return m_samples, b_samples, sigma2_samples, accepted / (n_iterations - burn_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c697651-05eb-4082-962e-144f86fd7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65725/530061145.py:40: RuntimeWarning: overflow encountered in exp\n",
      "  acceptance_prob = np.exp(proposed_log_post - current_log_post)\n",
      "/tmp/ipykernel_65725/530061145.py:60: RuntimeWarning: overflow encountered in exp\n",
      "  acceptance_prob = np.exp(proposed_log_post - current_log_post)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance fraction 0.6506122448979592\n",
      "Estimated m: 2.970686404535775\n",
      "Estimated b: 4.125086047917617\n",
      "Estimated sigma^2: 0.6888285329155968\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.normal(0, 1, 100)\n",
    "y_data = 3.0 * x_data + 4.0 + np.random.normal(0, np.sqrt(0.8), 100)\n",
    "\n",
    "# Define priors: (mean, variance) for normal, (alpha, beta) for inverse gamma\n",
    "reported_stat_err = 0.3\n",
    "m_prior = (2, 10)\n",
    "b_prior = (1, 10)\n",
    "sigma2_prior = (3, reported_stat_err / (3 - 1))\n",
    "\n",
    "# Run Metropolis-Hastings in batches\n",
    "m_samples, b_samples, sigma2_samples, acc_frac = metropolis_hastings_batched(\n",
    "    y_data,\n",
    "    x_data,\n",
    "    m_prior=m_prior,\n",
    "    b_prior=b_prior,\n",
    "    sigma2_prior=sigma2_prior,\n",
    "    proposal_std=(0.1, 0.1, 0.1),\n",
    "    n_iterations=10000,\n",
    ")\n",
    "print(f\"Acceptance fraction {acc_frac}\")\n",
    "print(\"Estimated m:\", np.mean(m_samples))\n",
    "print(\"Estimated b:\", np.mean(b_samples))\n",
    "print(\"Estimated sigma^2:\", np.mean(sigma2_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abc19d-08d7-49c4-98f8-0c58d235fcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
